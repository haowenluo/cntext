# ç®€ä»‹
## cntextï¼šé¢å‘ç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„ä¸­æ–‡æ–‡æœ¬åˆ†æå·¥å…·åº“

cntext æ˜¯ä¸“ä¸º**ç¤¾ä¼šç§‘å­¦å®è¯ç ”ç©¶è€…**è®¾è®¡çš„ä¸­æ–‡æ–‡æœ¬åˆ†æ Python åº“ã€‚å®ƒä¸æ­¢äºè¯é¢‘ç»Ÿè®¡å¼çš„ä¼ ç»Ÿæƒ…æ„Ÿåˆ†æï¼Œè¿˜æ‹¥æœ‰è¯åµŒå…¥è®­ç»ƒã€è¯­ä¹‰æŠ•å½±è®¡ç®—ï¼Œ**å¯ä»å¤§è§„æ¨¡éç»“æ„åŒ–æ–‡æœ¬ä¸­æµ‹é‡æŠ½è±¡æ„å¿µ**â€”â€”å¦‚æ€åº¦ã€è®¤çŸ¥ã€æ–‡åŒ–è§‚å¿µä¸å¿ƒç†çŠ¶æ€ã€‚

ğŸ¯ **ä½ èƒ½ç”¨å®ƒåšä»€ä¹ˆ**
1. æ„å»ºç»“æ„åŒ–ç ”ç©¶æ•°æ®é›†
   - æ±‡æ€»å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ˆtxt/pdf/docx/csvï¼‰ä¸º DataFrameï¼š``ct.read_files()``
   - æå–ä¸Šå¸‚å…¬å¸å¹´æŠ¥ä¸­çš„â€œç®¡ç†å±‚è®¨è®ºä¸åˆ†æâ€ï¼ˆMD&Aï¼‰ï¼š``ct.extract_mda()``
   - è®¡ç®—æ–‡æœ¬å¯è¯»æ€§æŒ‡æ ‡ï¼ˆå¦‚FleschæŒ‡æ•°ï¼‰ï¼š``ct.readability()``

2. **åŸºç¡€æ–‡æœ¬åˆ†æ(ä¼ ç»Ÿæ–¹æ³•)**
   - è¯é¢‘ç»Ÿè®¡ä¸å…³é”®è¯æå–ï¼š``ct.word_count()``
   - æƒ…æ„Ÿåˆ†æï¼ˆåŸºäºçŸ¥ç½‘ã€å¤§è¿ç†å·¥ç­‰è¯å…¸ï¼‰ï¼š``ct.sentiment()``
   - æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆä½™å¼¦è·ç¦»ï¼‰ï¼š``ct.cosine_sim()``

3. **æµ‹é‡å†…éšæ€åº¦ä¸æ–‡åŒ–å˜è¿**
   - ä¸¤è¡Œä»£ç è®­ç»ƒé¢†åŸŸä¸“ç”¨è¯å‘é‡ï¼ˆWord2Vec/GloVeï¼‰ï¼š``ct.Word2Vec()``
   - æ„å»ºæ¦‚å¿µè¯­ä¹‰è½´ï¼ˆå¦‚â€œåˆ›æ–° vs å®ˆæ—§â€ï¼‰ï¼š``ct.generate_concept_axis()``
   - é€šè¿‡è¯­ä¹‰æŠ•å½±é‡åŒ–åˆ»æ¿å°è±¡ã€ç»„ç»‡æ–‡åŒ–åç§»ï¼š``ct.project_text()``
4. **èåˆå¤§æ¨¡å‹è¿›è¡Œç»“æ„åŒ–åˆ†æ**
   - è°ƒç”¨ LLM å¯¹æ–‡æœ¬è¿›è¡Œè¯­ä¹‰è§£æï¼Œè¿”å›ç»“æ„åŒ–ç»“æœï¼ˆå¦‚æƒ…ç»ªç»´åº¦ã€æ„å›¾åˆ†ç±»ï¼‰ï¼š``ct.llm()``


cntext ä¸è¿½æ±‚é»‘ç®±é¢„æµ‹ï¼Œè€Œè‡´åŠ›äºè®©æ–‡æœ¬æˆä¸ºç†è®ºé©±åŠ¨çš„ç§‘å­¦æµ‹é‡å·¥å…·ã€‚ å¼€æºå…è´¹ï¼Œæ¬¢è¿å­¦ç•ŒåŒä»ä½¿ç”¨ã€éªŒè¯ä¸å…±å»ºã€‚

<br>


## æ¨¡å—

cntext2.x å«ioã€modelã€statsã€mindäº”ä¸ªæ¨¡å—

1. å¯¼å…¥æ•°æ®ç”¨io
2. è®­ç»ƒæ¨¡å‹æ‰©å±•è¯å…¸ç”¨model
3. ç»Ÿè®¡è¯é¢‘ã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼åº¦ç­‰ç”¨stats
4. å¯è§†åŒ–æ¨¡å—plot
5. æ€åº¦è®¤çŸ¥æ–‡åŒ–å˜è¿ç”¨mind
6. å¤§æ¨¡å‹LLM


<br>

| æ¨¡å— | å‡½æ•°                                        | åŠŸèƒ½                                        |
| -------- | ------------------------------------------- | ------------------------------------------- |
| ***io*** | ***ct.get_cntext_path()***                    | æŸ¥çœ‹cntextå®‰è£…è·¯å¾„                          |
| ***io*** | ***ct.get_dict_list()***                    | æŸ¥çœ‹cntextå†…ç½®è¯å…¸                          |
| ***io*** | ***ct.get_files(fformat)***                   | æŸ¥çœ‹ç¬¦åˆfformatè·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶         |
| ***io*** | ***ct.detect_encoding(file, num_lines=100)*** | è¯Šæ–­txtã€csvç¼–ç æ ¼å¼                        |
| ***io*** | ***ct.read_yaml_dict(yfile)***         | è¯»å–å†…ç½®yamlè¯å…¸                            |
| ***io*** | ***ct.read_pdf(file)***         | è¯»å–PDFæ–‡ä»¶                                    |
| ***io*** | ***ct.read_docx(file)***         | è¯»å–docxæ–‡ä»¶                                    |
| ***io*** | ***ct.read_file(file, encodings)***         | è¯»å–æ–‡ä»¶                                    |
| ***io*** | ***ct.read_files(fformat, encoding)***       | è¯»å–ç¬¦åˆfformatè·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å›df |
| ***io*** | ***ct.extract_mda(text, kws_pattern)***       | æå–Aè‚¡å¹´æŠ¥ä¸­çš„MD&Aæ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚ |
| ***io*** | ***ct.traditional2simple(text)***     | ç¹ä½“è½¬ç®€ä½“ |
| ***io*** | ***ct.fix_text(text)*** | å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’ |
| ***io*** | ***ct.fix_contractions(text)***                       | è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚you're -> you are                                      |
| ***model*** | ***ct.Word2Vec(corpus_file, encoding, lang='chinese', ...)***    | è®­ç»ƒWord2Vec                                     |
| ***model*** | ***ct.GloVe(corpus_file, encoding, lang='chinese', ...)***    | GloVe, åº•å±‚ä½¿ç”¨çš„ [Standfordnlp/GloVe](https://github.com/standfordnlp/GloVe)                                    |
| ***model*** | ***ct.glove2word2vec(glove_file, word2vec_file)***                 | å°†GLoVeæ¨¡å‹.txtæ–‡ä»¶è½¬åŒ–ä¸ºWord2Vecæ¨¡å‹.txtæ–‡ä»¶ï¼› ä¸€èˆ¬å¾ˆå°‘ç”¨åˆ°    |
| ***model*** | ***ct.evaluate_similarity(wv, file=None)***                | ä½¿ç”¨è¿‘ä¹‰æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚|
| ***model*** | ***ct.evaluate_analogy(wv, file=None)***                | ä½¿ç”¨ç±»æ¯”æ³•è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®çš„æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚|
| ***model*** |  ***project_word(wv, a, b, weight=None)***    |  åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œ è®¡ç®—è¯è¯­aåœ¨è¯è¯­bä¸Šçš„æŠ•å½±ã€‚|
| ***model*** | ***ct.load_w2v(wv_path)***                 | è¯»å–cntext2.xè®­ç»ƒå‡ºçš„Word2Vec/GloVeæ¨¡å‹æ–‡ä»¶       |
| ***model*** | ***ct.expand_dictionary(wv,  seeddict, topn=100)***            | æ‰©å±•è¯å…¸,  ç»“æœä¿å­˜åˆ°è·¯å¾„[output/Word2Vec]ä¸­ |
| ***model*** | ***ct.SoPmi(corpus_file, seed_file, lang='chinese')***         | å…±ç°æ³•æ‰©å±•è¯å…¸                                   |
| ***stats*** | ***ct.word_count(text, lang='chinese')***                       | è¯é¢‘ç»Ÿè®¡                                                 |
| ***stats*** | ***readability(text, lang='chinese', syllables=3)***                     | æ–‡æœ¬å¯è¯»æ€§                                               |
| ***stats*** | ***ct.sentiment(text, diction, lang='chinese')***            | æ— (ç­‰)æƒé‡è¯å…¸çš„æƒ…æ„Ÿåˆ†æ                                 |
| ***stats*** | ***ct.sentiment_by_valence(text, diction, lang='chinese')***   | å¸¦æƒé‡çš„è¯å…¸çš„æƒ…æ„Ÿåˆ†æ                                   |
| ***stats*** | ***ct.word_in_context(text, keywords, window=3, lang='chinese')*** | åœ¨textä¸­æŸ¥æ‰¾keywordså‡ºç°çš„ä¸Šä¸‹æ–‡å†…å®¹(çª—å£window)ï¼Œè¿”å›df |
| ***stats*** | ***ct.epu()***                                               | ä½¿ç”¨æ–°é—»æ–‡æœ¬æ•°æ®è®¡ç®—ç»æµæ”¿ç­–ä¸ç¡®å®šæ€§EPUï¼Œè¿”å›df          |
| ***stats*** | ***ct.fepu(text, ep_pattern='', u_pattern='')***             | ä½¿ç”¨md&aæ–‡æœ¬æ•°æ®è®¡ç®—ä¼ä¸šä¸ç¡®å®šæ€§æ„ŸçŸ¥FEPU                 |
| ***stats*** | ***ct.semantic_brand_score(text, brands, lang='chinese')***  | è¡¡é‡å“ç‰Œï¼ˆä¸ªä½“ã€å…¬å¸ã€å“ç‰Œã€å…³é”®è¯ç­‰ï¼‰çš„é‡è¦æ€§           |
| ***stats*** | ***ct.cosine_sim(text1, text2, lang='chinese')*** | ä½™å¼¦ç›¸ä¼¼åº¦    |
| ***stats*** | ***ct.jaccard_sim(text1, text2, lang='chinese')***  | Jaccardç›¸ä¼¼åº¦ |
| ***stats*** | ***ct.minedit_sim(text1, text2, lang='chinese')***  | æœ€å°ç¼–è¾‘è·ç¦»  |
| ***stats*** | ***ct.word_hhi(text)***  | æ–‡æœ¬çš„èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•° |
| ***plot*** | ***ct.matplotlib_chinese()***  | æ”¯æŒmatplotlibä¸­æ–‡ç»˜å›¾ |
| ***plot*** | ***ct.lexical_dispersion_plot1(text, targets_dict, lang, title, figsize)***  | å¯¹æŸä¸€ä¸ªæ–‡æœ¬textï¼Œ å¯è§†åŒ–ä¸åŒç›®æ ‡ç±»åˆ«è¯targets_dictåœ¨æ–‡æœ¬ä¸­å‡ºç°ä½ç½®  |
| ***plot*** | ***ct.lexical_dispersion_plot2(texts_dict, targets, lang, title, figsize)***  | å¯¹æŸå‡ ä¸ªæ–‡æœ¬texts_dictï¼Œ å¯è§†åŒ–æŸäº›ç›®æ ‡è¯targetsåœ¨æ–‡æœ¬ä¸­å‡ºç°ç›¸å¯¹ä½ç½®(0~100)  |
| ***mind***  | ``ct.generate_concept_axis(wv, c_words1, c_words2)`` | ç”Ÿæˆæ¦‚å¿µè½´å‘é‡ã€‚                                               |
| ***mind***  | ***tm = ct.Text2Mind(wv)***<br>                      | å•ä¸ªword2vecå†…æŒ–æ˜æ½œåœ¨çš„æ€åº¦åè§ã€åˆ»æ¿å°è±¡ç­‰ã€‚tmå«å¤šé‡æ–¹æ³• |
| ***mind***  | ***ct.sematic_projection(wv, words, c_words1, c_words2)*** | æµ‹é‡è¯­ä¹‰æŠ•å½±                                               |
| ***mind***  | ***ct.project_word(wv, a, b)*** | æµ‹é‡è¯è¯­aåœ¨è¯è¯­bä¸Šçš„æŠ•å½±è¯­                                              |
| **mind**  | ***ct.project_text(wv, text, axis, lang='chinese', cosine=False)***   | è®¡ç®—è¯è¯­æ–‡æœ¬textåœ¨æ¦‚å¿µè½´å‘é‡axisä¸Šçš„æŠ•å½±å€¼|
| ***mind***  | ***ct.sematic_distance(wv, words, c_words1, c_words2)*** | æµ‹é‡è¯­ä¹‰è·ç¦»                                               |
| ***mind***  | ***ct.divergent_association_task(wv, words)***       | æµ‹é‡å‘æ•£æ€ç»´(åˆ›é€ åŠ›)                                       |
| ***mind***  | ***ct.discursive_diversity_score(wv, words)***       | æµ‹é‡è¯­è¨€å·®å¼‚æ€§(è®¤çŸ¥å·®å¼‚æ€§)                                       |
| ***mind*** | ***ct.procrustes_align(base_wv, other_wv)*** | ä¸¤ä¸ªword2vecè¿›è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¯ååº”éšæ—¶é—´çš„ç¤¾ä¼šè¯­ä¹‰å˜è¿       |
| ***LLM*** | ***analysis_by_llm(text, prompt, base_url, api_key, model_name, temperature, output_format)*** | ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†æ        |


