
# ä¸€ã€IOæ¨¡å—

| æ¨¡å—     | å‡½æ•°                                        | åŠŸèƒ½                                                       |
| -------- | ------------------------------------------- | ---------------------------------------------------------- |
| ***io*** | ***ct.get_dict_list()***                    | æŸ¥çœ‹cntextå†…ç½®è¯å…¸                                         |
| ***io*** | ***ct.read_yaml_dict(yfile)***              | è¯»å–å†…ç½®yamlè¯å…¸                                           |
| ***io*** | ***ct.detect_encoding(file, num_lines=100)*** | è¯Šæ–­txtã€csvç¼–ç æ ¼å¼                                       |
| ***io*** | ***ct.get_files(fformat)***                  | æŸ¥çœ‹ç¬¦åˆfformatè·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶                        |
| ***io*** | ***ct.read_yaml_dict(yfile)***              | è¯»å–å†…ç½®yamlè¯å…¸                                           |
| ***io*** | ***ct.read_pdf(file)***                     | è¯»å–PDFæ–‡ä»¶                                                |
| ***io*** | ***ct.read_file(file, encoding)***          | è¯»å–æ–‡ä»¶                                                   |
| ***io*** | ***ct.read_files(fformat, encoding)***      | è¯»å–ç¬¦åˆfformatè·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œè¿”å›df                |
| ***io*** | ***ct.extract_mda(text, kws_pattern)***     | æå–Aè‚¡å¹´æŠ¥ä¸­çš„MD&Aæ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚       |
| ***io*** | ***ct.traditional2simple(text)***           | ç¹ä½“è½¬ç®€ä½“                                                 |
| ***io*** | ***ct.fix_text(text)***                     | å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’ |
| ***io*** | ***ct.fix_contractions(text)***                       | è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)å¤„ç†ï¼Œ å¦‚you're -> you are                                      |
| **io** | `ct.clean_text(text, lang='chinese')`               | ä¸­æ–‡ã€è‹±æ–‡æ–‡æœ¬æ¸…æ´—         |




## 1.1 get_dict_list()

æŸ¥çœ‹cntextå†…ç½®è¯å…¸

```python
import cntext as ct

ct.get_dict_list()
```

Run

```
['zh_common_NTUSD.yaml',
 'zh_common_DUTIR.yaml',
 'enzh_common_StopWords.yaml',
 'en_valence_Concreteness.yaml',
 'en_common_LoughranMcDonald.yaml',
 'zh_common_FinanceSenti.yaml',
 'zh_common_FLS.yaml',
 'zh_common_TsinghuaPraiseDegrade.yaml',
 'zh_common_FEPU.yaml',
 'en_common_ANEW.yaml',
 'en_common_NRC.yaml',
 'zh_valence_ChineseEmoBank.yaml',
 'zh_valence_SixSemanticDimensionDatabase.yaml',
 'zh_common_FinacialFormalUnformal.yaml',
 'zh_common_LoughranMcDonald.yaml',
 'enzh_common_AdvConj.yaml',
 'en_common_SentiWS.yaml',
 'zh_common_Digitalization.yaml',
 'en_common_LSD2015.yaml',
 'zh_common_HowNet.yaml',
 'zh_common_EPU.yaml']
```

## 1.2 å†…ç½®yamlè¯å…¸

| pklæ–‡ä»¶                                            | è¯å…¸                                                         | è¯­è¨€    | åŠŸèƒ½                                                         |
| -------------------------------------------------- | ------------------------------------------------------------ | ------- | ------------------------------------------------------------ |
| ***zh_valence_ChineseEmoBank.yaml***               | ä¸­æ–‡æƒ…æ„Ÿè¯å…¸ï¼Œå«``æ•ˆä»·valence``å’Œ``å”¤é†’åº¦arousal``ã€‚åœ¨cntextä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº†CVAWè¯è¡¨(å•è¯)ï¼Œå…¶ä»–è¯å…¸å¦‚CVAP, CVAS, CVATæ²¡æœ‰çº³å…¥åˆ°ChineseEmoBank.pkl. | Chinese | ``æ•ˆä»·valence``å’Œ``å”¤é†’åº¦arousal``                           |
| ***zh_common_DUTIR.yaml***                         | å¤§è¿ç†å·¥å¤§å­¦æƒ…æ„Ÿæœ¬ä½“åº“                                       | ä¸­æ–‡    | ä¸ƒå¤§ç±»æƒ…ç»ªï¼Œ``å“€, å¥½, æƒŠ, æƒ§, ä¹, æ€’, æ¶``                   |
| ***zh_common_HowNet.yaml***                        | çŸ¥ç½‘Hownetè¯å…¸                                               | ä¸­æ–‡    | æ­£é¢è¯ã€è´Ÿé¢è¯                                               |
| ***en_common_SentiWS.yaml***                       | SentimentWortschatz (SentiWS)                                | å¾·æ–‡    | æ­£é¢è¯ã€è´Ÿé¢è¯ï¼›<br>                                         |
| ***zh_common_FinacialFormalUnformal.yaml***        | é‡‘èé¢†åŸŸæ­£å¼ã€éæ­£å¼ï¼›ç§¯ææ¶ˆæ                               | ä¸­æ–‡    | formal-posã€<br>formal-negï¼›<br>unformal-posã€<br>unformal-neg |
| ***en_common_ANEW.yaml***                            | è‹±è¯­å•è¯çš„æƒ…æ„Ÿè§„èŒƒAffective Norms for English Words (ANEW)   | è‹±æ–‡    | pleasure, arousal, dominance                                 |
| ***en_common_LSD2015.yaml***                        | Lexicoder Sentiment Dictionary (2015)                        | è‹±æ–‡    | æ­£é¢è¯ã€è´Ÿé¢è¯                                               |
| ***en_common_NRC.yaml***                            | NRC Word-Emotion Association Lexicon                         | è‹±æ–‡    | ç»†ç²’åº¦æƒ…ç»ªè¯ï¼›                                               |
| ***zh_valence_SixSemanticDimensionDatabase.yaml*** | [**é€šç”¨ä¸­è‹±æ–‡å…­ç»´è¯­ä¹‰æƒ…æ„Ÿè¯å…¸**](https://textdata.cn/blog/2023-03-20-nature-six-semantic-dimension-database/), å«17940ä¸ªä¸­æ–‡è¯çš„å…­ç»´åº¦è¯åº“ï¼Œ ä¸”æ¯ä¸ªç»´åº¦æœ‰æƒé‡ã€‚ | ä¸­æ–‡    | visionã€socialnessã€emotionã€timeã€spaceã€motor              |
| ***enzh_common_AdvConj.yaml***                  | å‰¯è¯è¿è¯                                                     | ä¸­ã€è‹±  |                                                              |
| ***enzh_common_StopWords.yaml***                   | ä¸­è‹±æ–‡åœç”¨è¯                                                 | ä¸­ã€è‹±  | åœç”¨è¯                                                       |
| ***en_valence_Concreteness.yaml***                 | [è‹±æ–‡å…·ä½“æ€§è¯å…¸](https://textdata.cn/blog/jcr_concreteness_computation/) | English | word & concreateness score                                   |
| ***zh_common_LoughranMcDonald.yaml***              | ä¸­æ–‡LoughranMcDonaldè¯å…¸                                     | ä¸­æ–‡    | æ­£é¢ã€è´Ÿé¢è¯                                                 |
| ***zh_common_Digitalization.yaml***                | [ç®¡ç†ä¸–ç•Œ\|å´é(2021)æ•°å­—åŒ–è¯å…¸](https://textdata.cn/blog/2022-11-03-mda-measure-digitalization/) | ä¸­æ–‡    | å«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚ |
| ***en_common_LoughranMcDonald.yaml***              | è‹±æ–‡LoughranMcDonaldè¯å…¸                                     | è‹±æ–‡    | é‡‘èLMæƒ…ç»ªè¯å…¸2018å¹´ç‰ˆæœ¬ï¼Œå«ä¸ƒä¸ªè¯è¡¨ï¼Œåˆ†åˆ«æ˜¯Negative, Positive, Uncertainty, Litigious, StrongModal, WeakModal, Constraining |
| ***zh_common_FLS.yaml***                           | [**ä¸šç»©è¯´æ˜ä¼šå‰ç»æ€§è¯å…¸é›†**](https://textdata.cn/blog/2023-09-08-earnings-communication-conference-forward-looking-statements-information/) | ä¸­æ–‡    | å«174ä¸ªè¯è¯­                                                  |
| ***zh_common_RhetoricalNationalism.yaml***                           | ä¿®è¾æ°‘æ—ä¸»ä¹‰ | ä¸­æ–‡    | å«å››ä¸ªç»´åº¦ï¼Œæ°‘æ—è‡ªè±ªæ„Ÿã€æ°‘æ—å¤å…´ã€ä¼ä¸šè§’è‰²ã€æ’å¤–ä¸»ä¹‰ï¼Œæ¯ä¸ªç»´åº¦100ä¸ªè¯ã€‚                                                 |



<br>

## 1.3 read_dict_yaml()

ä½¿ç”¨ cntext è¯»å– ***.yaml*** è¯å…¸æ–‡ä»¶ï¼›  è¿”å›çš„ä¿¡æ¯åŒ…æ‹¬

- Name è¯å…¸çš„åå­—
- Desc è¯å…¸çš„å«ä¹‰ã€æ¦‚å¿µè§£é‡Š
- Refer è¯å…¸æ–‡çŒ®å‡ºå¤„
- Category è¯å…¸Dictionaryçš„å…³é”®è¯
- Dictionary è¯å…¸, pythonå­—å…¸æ ¼å¼

<br>

```python
import cntext as ct
print(ct.read_yaml_dict('zh_common_Digitalization.yaml'))
```

Run

```
{'Name': 'ä¸­æ–‡æ•°å­—åŒ–è¯å…¸', 
'Desc': 'åŸºäºè¿™ç¯‡è®ºæ–‡ï¼Œæ„å»ºäº†ä¸­æ–‡æ•°å­—åŒ–è¯å…¸ï¼Œå«äººå·¥æ™ºèƒ½æŠ€æœ¯ã€å¤§æ•°æ®æŠ€æœ¯ã€äº‘è®¡ç®—æŠ€æœ¯ã€åŒºå—é“¾æŠ€æœ¯ã€æ•°å­—æŠ€æœ¯åº”ç”¨ç­‰å…³é”®è¯åˆ—è¡¨ã€‚ ', 'Refer': 'å´é,èƒ¡æ…§èŠ·,æ—æ…§å¦,ä»»æ™“æ€¡. ä¼ä¸šæ•°å­—åŒ–è½¬å‹ä¸èµ„æœ¬å¸‚åœºè¡¨ç°â€”â€”æ¥è‡ªè‚¡ç¥¨æµåŠ¨æ€§çš„ç»éªŒè¯æ®[J]. ç®¡ç†ä¸–ç•Œ,2021,37(07):130-144+10.', 
'Category': ['Artificial_Intelligence', 'Big_Data', 'Cloud_Computing', 'Block_Chains', 'Usage_of_Digitalization'], 

'Dictionary': 
    {'Artificial_Intelligence': ['äººå·¥æ™ºèƒ½', 'å•†ä¸šæ™ºèƒ½', 'å›¾åƒç†è§£', 'æŠ•èµ„å†³ç­–è¾…åŠ©ç³»ç»Ÿ', 'æ™ºèƒ½æ•°æ®åˆ†æ', 'æ™ºèƒ½æœºå™¨äºº', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'è¯­ä¹‰æœç´¢', 'ç”Ÿç‰©è¯†åˆ«æŠ€æœ¯', 'äººè„¸è¯†åˆ«', 'è¯­éŸ³è¯†åˆ«', 'èº«ä»½éªŒè¯', 'è‡ªåŠ¨é©¾é©¶', 'è‡ªç„¶è¯­è¨€å¤„ç†'], 
    'Big_Data': ['å¤§æ•°æ®', 'æ•°æ®æŒ–æ˜', 'æ–‡æœ¬æŒ–æ˜', 'æ•°æ®å¯è§†åŒ–', 'å¼‚æ„æ•°æ®', 'å¾ä¿¡', 'å¢å¼ºç°å®', 'æ··åˆç°å®', 'è™šæ‹Ÿç°å®'], 
    'Cloud_Computing': ['äº‘è®¡ç®—', 'æµè®¡ç®—', 'å›¾è®¡ç®—', 'å†…å­˜è®¡ç®—', 'å¤šæ–¹å®‰å…¨è®¡ç®—', 'ç±»è„‘è®¡ç®—', 'ç»¿è‰²è®¡ç®—', 'è®¤çŸ¥è®¡ç®—', 'èåˆæ¶æ„', 'äº¿çº§å¹¶å‘', 'EBçº§å­˜å‚¨', 'ç‰©è”ç½‘', 'ä¿¡æ¯ç‰©ç†ç³»ç»Ÿ'], 
    'Block_Chains': ['åŒºå—é“¾', 'æ•°å­—è´§å¸', 'åˆ†å¸ƒå¼è®¡ç®—', 'å·®åˆ†éšç§æŠ€æœ¯', 'æ™ºèƒ½é‡‘èåˆçº¦'], 
    'Usage_of_Digitalization': ['ç§»åŠ¨äº’è”ç½‘', 'å·¥ä¸šäº’è”ç½‘', 'ç§»åŠ¨äº’è”', 'äº’è”ç½‘åŒ»ç–—', 'ç”µå­å•†åŠ¡', 'ç§»åŠ¨æ”¯ä»˜', 'ç¬¬ä¸‰æ–¹æ”¯ä»˜', 'NFCæ”¯ä»˜', 'æ™ºèƒ½èƒ½æº', 'B2B', 'B2C', 'C2B', 'C2C', 'O2O', 'ç½‘è”', 'æ™ºèƒ½ç©¿æˆ´', 'æ™ºæ…§å†œä¸š', 'æ™ºèƒ½äº¤é€š', 'æ™ºèƒ½åŒ»ç–—', 'æ™ºèƒ½å®¢æœ', 'æ™ºèƒ½å®¶å±…', 'æ™ºèƒ½æŠ•é¡¾', 'æ™ºèƒ½æ–‡æ—…', 'æ™ºèƒ½ç¯ä¿', 'æ™ºèƒ½ç”µç½‘', 'æ™ºèƒ½è¥é”€', 'æ•°å­—è¥é”€', 'æ— äººé›¶å”®', 'äº’è”ç½‘é‡‘è', 'æ•°å­—é‡‘è', 'Fintech', 'é‡‘èç§‘æŠ€', 'é‡åŒ–é‡‘è', 'å¼€æ”¾é“¶è¡Œ']}}
```

<br>

## 1.4 detect_encoding()

é€šè¿‡è¯»å–å‰num_linesæ¥è¯†åˆ«txt/csvæ–‡ä»¶çš„ç¼–ç æ ¼å¼
```
ct.detect_encoding(file)
```

- ***file*** æ–‡ä»¶è·¯å¾„

<br>

```python
import cntext as ct

# è¯»å–dataæ–‡ä»¶å¤¹ä¸‹çš„ã€Œä¸‰ä½“.txtã€
# è¯†åˆ«ç¼–ç æ–¹å¼
ct.detect_encoding(file='data/ä¸‰ä½“.txt')
```

Run

```
utf-8
```

<br>

## 1.5 get_files(fformat)

- **fformat**  fformatæ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csvç­‰ã€‚ ``*``è¡¨ç¤ºé€šé…ç¬¦

æŸ¥çœ‹ç¬¦åˆfformatè·¯å¾„è§„åˆ™çš„æ‰€æœ‰çš„æ–‡ä»¶ï¼Œ fformatæ ¼å¼æ”¯æŒ txt/pdf/docx/xlsx/csvç­‰ã€‚ ``*``è¡¨ç¤ºé€šé…ç¬¦

| fformatæ ¼å¼    | è¯†åˆ«çš„æ–‡ä»¶                      |
| -------------- | ------------------------------- |
| ``*.txt``      | åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰txt |
| ``*.pdf``      | åŒ¹é…å½“å‰ä»£ç æ‰€åœ¨è·¯å¾„å†…çš„æ‰€æœ‰pdf |
| ``data/*.txt`` | åŒ¹é…ã€Œæ–‡ä»¶å¤¹dataã€å†…æ‰€æœ‰çš„ txt  |

<br>  

```python
# æŸ¥çœ‹ã€Œæ–‡ä»¶å¤¹dataã€å†…æ‰€æœ‰çš„ txtæ–‡ä»¶ã€‚
ct.get_files(fformat='data/*.txt')
```

Run

```
['data/ä¸‰ä½“.txt',
 'data/santi.txt',
 'data/w2v_corpus.txt',
 'data/sopmi_corpus.txt',
 'data/brown_corpus.txt',
 'data/sopmi_seed_words.txt']
```

<br>

## 1.6 read_pdf

è¯»å–PDFï¼Œè¿”å›æ–‡æœ¬å†…å®¹

```python
ct.read_pdf(file)
```

- ***file*** PDFæ–‡ä»¶è·¯å¾„

ç‚¹å‡» [**æ ¼åŠ›ç”µå™¨2023.pdf**](https://textdata.cn/data/æ ¼åŠ›ç”µå™¨2023.pdf)

<br>

```python
import cntext as ct

text = ct.read_pdf('æ ¼åŠ›ç”µå™¨2023.pdf')
print(text) 
```

Run

```
ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡  
ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸  
2023å¹´å¹´åº¦æŠ¥å‘Š  
 
 
äºŒã€‡äºŒå››å¹´å››æœˆ 
ç æµ·æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸ 2023å¹´å¹´åº¦æŠ¥å‘Šå…¨æ–‡  
 ç¬¬ 2 é¡µ å…± 249 é¡µ ç¬¬ä¸€èŠ‚ é‡è¦æç¤ºã€ç›®å½•å’Œé‡Šä¹‰  
å…¬å¸è‘£äº‹ä¼šã€ç›‘äº‹ä¼šåŠè‘£äº‹ã€ç›‘äº‹ã€é«˜çº§ç®¡ç†äººå‘˜ä¿è¯å¹´åº¦æŠ¥å‘Šå†…å®¹
çš„çœŸå®ã€å‡†ç¡®ã€å®Œæ•´ï¼Œä¸å­˜åœ¨è™šå‡è®°è½½ã€è¯¯å¯¼æ€§é™ˆè¿°æˆ–é‡å¤§é—æ¼ï¼Œå¹¶æ‰¿æ‹…
ä¸ªåˆ«å’Œè¿å¸¦çš„æ³•å¾‹
......
```

<br>

## 1.7 read_docx

è¯»å–docxï¼Œè¿”å›æ–‡æœ¬å†…å®¹

```python
ct.read_docx(file)
```

- ***file*** docxæ–‡ä»¶è·¯å¾„

<br>

```python
import cntext as ct

text = ct.read_docx('test.docx')
text
```

Run

```
è¿™æ˜¯æ¥è‡ªtest.docxé‡Œå†…å®¹
```

<br>



## 1.8 read_file()

è¯»å–æ–‡ä»¶ï¼Œè¿”å›æ–‡æœ¬å†…å®¹

```
ct.read_file(file, encoding='utf-8')
```

- **file** å¾…è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼› æ”¯æŒtxtã€pdfã€docxã€xlsxã€xlsï¼Œ è¿”å› DataFrame(å«docå’Œfileä¸¤ä¸ªå­—æ®µ)ã€‚
- **encoding** å¾…è¯»å–æ–‡ä»¶çš„ç¼–ç æ–¹å¼

ä»¥ ``data/ä¸‰ä½“.txt`` ä¸ºä¾‹

<br>

```python
import cntext as ct

# é»˜è®¤encoding='utf-8'
# sdf = ct.read_file(file='data/ä¸‰ä½“.txt')

sdf = ct.read_file(file='data/ä¸‰ä½“.txt', encoding='utf-8')
sdf
```

![](img/01-san_ti_df.png)

<br>



## 1.9 read_files()

```
ct.read_files(fformat, encoding='utf-8'ï¼‰
```

æ‰¹é‡è¯»å–ç¬¦åˆfformatæ ¼å¼çš„æ‰€æœ‰æ–‡ä»¶æ•°æ®ï¼Œè¿”å›DataFrame(å«docå’Œfileä¸¤ä¸ªå­—æ®µ)ã€‚

è¯»å–[æ–‡ä»¶å¤¹dataé‡Œæ‰€æœ‰txt]

<br>

```python
import cntext as ct

# é»˜è®¤encoding='utf-8'
# ddf = ct.read_files(fformat='data/*.txt')

ddf = ct.read_files(fformat='data/*.txt', encoding='utf-8')
ddf
```

![](img/02-ddf.png)


<br>

## 1.10 extract_mda
æå–Aè‚¡å¹´æŠ¥ä¸­çš„MD&Aæ–‡æœ¬å†…å®¹ã€‚å¦‚æœè¿”å›'',åˆ™æå–å¤±è´¥ã€‚

```
ct.extract_mda(text, kws_pattern='')
```
- text ä¸­å›½Aè‚¡å¹´æŠ¥åŸå§‹æ–‡æœ¬
- kws_pattern ç®¡ç†å±‚è®¨è®ºä¸åˆ†æç« èŠ‚è¯†åˆ«å…³é”®è¯çš„æ¨¡æ¿ã€‚cntextå†…ç½®çš„kws_patternå†…å®¹å¦‚ä¸‹

```
kws_pattern = 'è‘£äº‹ä¼šæŠ¥å‘Š|è‘£äº‹ä¼šæŠ¥å‘Šä¸ç®¡ç†è®¨è®º|ä¼ä¸šè¿è¥ä¸ç®¡ç†è¯„è¿°|ç»è¥æ€»ç»“ä¸åˆ†æ|ç®¡ç†å±‚è¯„ä¼°ä¸æœªæ¥å±•æœ›|è‘£äº‹å±€æŠ¥å‘Š|ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ|ç»è¥æƒ…å†µè®¨è®ºä¸åˆ†æ|ç»è¥ä¸šç»©åˆ†æ|ä¸šåŠ¡å›é¡¾ä¸å±•æœ›|å…¬å¸ç»è¥åˆ†æ|ç®¡ç†å±‚è¯„è®ºä¸åˆ†æ|æ‰§è¡Œæ‘˜è¦ä¸ä¸šåŠ¡å›é¡¾|ä¸šåŠ¡è¿è¥åˆ†æ'
```

<br>

```python
import cntext as ct

text = ct.read_pdf('æ ¼åŠ›ç”µå™¨2023.pdf')
mda_text = ct.extract_mda(text)
print(mda_text)
```
Run

```
'ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ  \nä¸€ã€æŠ¥å‘ŠæœŸå†…å…¬å¸æ‰€å¤„è¡Œä¸šæƒ…å†µ  \nï¼ˆä¸€ï¼‰è¡Œä¸šå‘å±•ç°çŠ¶  \n1.æ¶ˆè´¹é¢†åŸŸ â€”â€”å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ï¼Œç©ºè°ƒå¸‚åœºæ¢å¤æ˜æ˜¾  \n2023å¹´ï¼Œä¸­å›½ç»æµä¿æŒäº†æ•´ä½“æ¢å¤å‘å¥½çš„æ€åŠ¿ï¼Œæ¿€å‘æ¶ˆè´¹æ˜¯ç¨³å¢é•¿çš„é‡ä¸­ä¹‹é‡ã€‚å›½å®¶é¼“åŠ±å’Œæ¨åŠ¨æ¶ˆè´¹å“ä»¥æ—§æ¢\næ–°ï¼Œä¿ƒè¿›æ¶ˆè´¹ç»æµå¤§å¾ªç¯ï¼ŒåŠ é€Ÿæ›´æ–°éœ€æ±‚é‡Šæ”¾ï¼Œæ¨åŠ¨é«˜èƒ½æ•ˆäº§å“è®¾å¤‡é”€å”®å’Œå‡ºå£å¢é•¿ï¼Œè¿›ä¸€æ­¥æ¿€å‘ç»¿è‰²æ¶ˆè´¹æ½œåŠ›ã€‚  \n1ï¼‰å®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿  \n2023å¹´ï¼Œå›½å†…ç»æµæ¢å¤æ˜æ˜¾ï¼Œå®¶ç”µè¡Œä¸šç¨³å®šå¢é•¿ã€‚æ ¹æ®å…¨å›½å®¶ç”¨ç”µå™¨å·¥ä¸šä¿¡æ¯ä¸­å¿ƒå‘å¸ƒçš„ã€Š 2023å¹´ä¸­å›½å®¶ç”µ\nè¡Œä¸šå¹´åº¦æŠ¥å‘Šã€‹ï¼Œå®¶ç”µè¡Œä¸šå¤–é”€æ˜æ˜¾å¢é•¿ï¼Œå‡ºå£è§„æ¨¡ä¸º 6,174äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿ 9.9%ï¼›å›½å†…å¸‚åœºå®ç°ç¨³æ­¥å¢é•¿ï¼Œé”€å”®\nè§„æ¨¡ä¸º7'
.......
.......
```

<br>

ä»¥[2001å¹´~2023ä¼šè®¡å¹´åº¦æŠ¥å‘Šæ•°æ®é›†](https://textdata.cn/blog/2023-03-23-china-a-share-market-dataset-mda-from-01-to-21/)ä¸ºä¾‹ï¼Œ æŸ¥çœ‹ ***extract_mda*** çš„æŠ½å–mdaçš„èƒ½åŠ›ã€‚ 

```python
import glob
import cntext as ct

print('extract_mdaè¯†åˆ«èƒ½åŠ›')
for year in range(2001, 2024):
    num = 0
    for file in glob.glob(f'å¹´æŠ¥txt/{year}/*.txt'):
        mda_text = ct.extract_mda(open(file).read())
        if mda_text!='':
            num = num + 1
               
    volume = len(glob.glob(f'å¹´æŠ¥txt/{year}/*.txt'))     
    ratio = num/volume
    
    print(f'{year}: {ratio:.2f}')
```

Run

```
2001: 0.24
2002: 0.37
2003: 0.43
2004: 0.70
2005: 0.77
2006: 0.78
2007: 0.79
2008: 0.77
2009: 0.79
2010: 0.82
2011: 0.84
2012: 0.96
2013: 0.95
2014: 0.98
2015: 0.98
2016: 0.99
2017: 0.98
2018: 0.98
2019: 0.99
2020: 0.97
2021: 0.98
2022: 0.99
2023: 0.99
```

å»ºè®®å„ä½ç”¨æœ€è¿‘10å¹´çš„å¹´æŠ¥æ•°æ®ï¼Œé€šè¿‡extract_mdaæå–mdaæ–‡æœ¬ï¼Œæˆ–è€…ç›´æ¥è´­ä¹° [æ•°æ®é›† | 2001-2023å¹´Aè‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥&ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ](æ•°æ®é›† | 2001-2023å¹´Aè‚¡ä¸Šå¸‚å…¬å¸å¹´æŠ¥&ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ)

<br>



## 1.11 traditional2simple()

ç¹ä½“è½¬ç®€ä½“

```
ct.traditional2simple(text, mode='t2s')
```

- ***text*** å¾…è½¬æ¢çš„æ–‡æœ¬
- ***mode*** è½¬æ¢æ¨¡å¼ï¼Œ é»˜è®¤mode='t2s'ç¹è½¬ç®€; modeè¿˜æ”¯æŒs2t

 <br>

```python
import cntext as ct

text = 'ç°¡é«”æ¼¢å­—'
ct.traditional2simple(text)
```

Run

```
'ç®€ä½“æ±‰å­—'
```



<br>

```python
text = 'ç®€ä½“æ±‰å­—'
ct.traditional2simple(text, mode='s2t')
```

Run

```
'ç°¡é«”æ¼¢å­—'
```

<br>

## 1.12 fix_text()
å°†ä¸æ­£å¸¸çš„ã€æ··ä¹±ç¼–ç çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¸¸çš„æ–‡æœ¬ã€‚ä¾‹å¦‚å…¨è§’è½¬åŠè§’

<br>


```python
import cntext as ct

raw_text = 'ä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯ï¼ï¼“ï¼—ï¼‘ï¼ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼™ï¼‘ã€ï¼–ï¼–ï¼“ï¼’ï¼‘ï¼™ï¼—ï¼“å’¨è¯¢ã€‚'

text = ct.fix_text(raw_text)
text
```
Run
```
ä»Šæ—¥èµ·å¯ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå¯ä»¥æ‹¨æ‰“ç”µè¯0371-66321991ã€66321973å’¨è¯¢ã€‚
```
<br>

## 1.13 fix_contractions(text)
å°†è‹±æ–‡ç¼©å†™(å«ä¿šè¯­è¡¨è¾¾)è½¬åŒ–ä¸ºå®Œæ•´çš„è¡¨è¾¾ï¼Œå¦‚å¦‚

```
- you're -> you are
- yall  -> you all
- gotta  -> got to
...
```

<br>

```python
import cntext as ct

raw_text = "yall're happy now"

text = ct.fix_contractions(raw_text)
text
```
Run
```
"you all are happy now"
```



### 1.13 clean_text(text)

```python
ct.clean_text(text, lang='chinese')
```

- **_text_** å¾…å¤„ç†çš„æ–‡æœ¬
- **_lang_** è¯­è¨€ç±»å‹ï¼Œ é»˜è®¤ lang='chinese', æ”¯æŒ"english"ã€"chinese"

```python
import cntext as ct

chinese_text = ("ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚"
                "æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡")

print(">>> ä¸­æ–‡æ¸…æ´—")
print("åŸå§‹:", repr(chinese_text))
print("æ¸…æ´—:", repr(ct.clean_text(chinese_text, lang="chinese")))
print()

    # è‹±æ–‡æµ‹è¯•
english_text = ("Great workout today! Ran 5.6 miles, HR stable. "
                "Check https://example.com/data ğŸ˜Š #Fitness")
print(">>> è‹±æ–‡æ¸…æ´—")
print("åŸå§‹:", repr(english_text))
print("æ¸…æ´—:", repr(ct.clean_text(english_text, lang="english")))
```
Run
```
>>> ä¸­æ–‡æ¸…æ´—
åŸå§‹: 'ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†5.6å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹ https://example.com/data ğŸ˜Š #å¥èº«æ‰“å¡'
æ¸…æ´—: 'ä»Šå¤©çš„è®­ç»ƒå¾ˆæ£’ï¼è·‘äº†æ•°å­—å…¬é‡Œï¼Œå¿ƒç‡ç¨³å®šã€‚æŸ¥çœ‹   å¥èº«æ‰“å¡'

>>> è‹±æ–‡æ¸…æ´—
åŸå§‹: 'Great workout today! Ran 5.6 miles, HR stable. Check https://example.com/data ğŸ˜Š #Fitness'
æ¸…æ´—: 'great workout today! ran NUMBER miles, hr stable. check  ğŸ˜Š #fitness'
```